# Server Configuration
PORT=5050

# Groq Configuration
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=deepseek-r1-distill-llama-70b

# Available Groq Models:
# - deepseek-r1-distill-llama-70b (default, powerful reasoning)
# - llama-3.3-70b-versatile (versatile, high quality)
# - llama-3.1-8b-instant (fast, lightweight)
# - mixtral-8x7b-32768 (good balance of speed and quality)
# - gemma2-9b-it (Google's compact model)
# See https://console.groq.com/docs/models for all available models

# GitHub Configuration (optional, for higher rate limits)
GITHUB_TOKEN=your_github_token_here
